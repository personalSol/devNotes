---
created: 2025-06-01T13:00:40
updated: 2025-06-01T15:33
status: 
source: 
---
---


- llm's are predicting models
- these large models are trained and updated once every year
- they can predict things but they can't
	- compute/caluculate or execute things ( like running a python script )
	- simple tasks like `2+2` or `finding no of r in straberry`
	- it's like it meorizes that that's the next word if someone writes 2 + 2 ( which it learns during training )
	- but if we give it a complex computation which it isn't trained with 
		- ex: `742829879*7882347892` then without taking external help it can't answer this as it wasn't trained with this computation
- for such these tasks, they take help of external tools
- a pure LLM model can only and only predict next words
- the response we get is based on the data we trained the model with
	- if we train it with wrong data then it will product wrong output
‚úÖ LLMs process text ‚Äî  
‚ùå They don‚Äôt ‚Äúremember‚Äù anything themselves.  
üß© Memory and personalization = achieved via **external tooling** + clever prompt engineering.

